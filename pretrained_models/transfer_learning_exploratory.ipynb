{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('./..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mconfig_models\u001b[m\u001b[m        img_test.jpg         \u001b[1m\u001b[36mnotebooks\u001b[m\u001b[m\n",
      "constants.py         load_and_training.py predict.py\n",
      "\u001b[1m\u001b[36mdata_folder\u001b[m\u001b[m          \u001b[1m\u001b[36mlog_monitoring\u001b[m\u001b[m       pretrained_main.py\n",
      "\u001b[1m\u001b[36mdataset_structure\u001b[m\u001b[m    main.py              \u001b[1m\u001b[36mpretrained_models\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[36mevaluation_metrics\u001b[m\u001b[m   \u001b[1m\u001b[36mmodels\u001b[m\u001b[m               \u001b[1m\u001b[36mutils\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ConvNextModel, ResNetModel, T5ForConditionalGeneration, T5Tokenizer\n",
    "from data_folder.medical_datasets import RocoDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages/transformers-4.20.0.dev0-py3.8.egg/transformers/models/t5/tokenization_t5.py:164: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "roco_path = \"/Users/pdcos/Documents/Mestrado/IA025/Projeto_Final/Code/caption_medical_images/dataset_structure/roco-dataset\"\n",
    "train_dataset = RocoDataset(roco_path=roco_path, mode=\"train\", caption_max_length=64, tokenizer=tokenizer)\n",
    "valid_dataset = RocoDataset(roco_path=roco_path, mode=\"validation\", caption_max_length=64, tokenizer=tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=3, shuffle=True, drop_last=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=3, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/convnext-tiny-224 were not used when initializing ConvNextModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing ConvNextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ConvNextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = ConvNextModel.from_pretrained(\"facebook/convnext-tiny-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNextModel(\n",
       "  (embeddings): ConvNextEmbeddings(\n",
       "    (patch_embeddings): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (layernorm): ConvNextLayerNorm()\n",
       "  )\n",
       "  (encoder): ConvNextEncoder(\n",
       "    (stages): ModuleList(\n",
       "      (0): ConvNextStage(\n",
       "        (downsampling_layer): Identity()\n",
       "        (layers): Sequential(\n",
       "          (0): ConvNextLayer(\n",
       "            (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "            (layernorm): ConvNextLayerNorm()\n",
       "            (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELUActivation()\n",
       "            (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): ConvNextLayer(\n",
       "            (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "            (layernorm): ConvNextLayerNorm()\n",
       "            (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELUActivation()\n",
       "            (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): ConvNextLayer(\n",
       "            (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
       "            (layernorm): ConvNextLayerNorm()\n",
       "            (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (act): GELUActivation()\n",
       "            (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ConvNextStage(\n",
       "        (downsampling_layer): Sequential(\n",
       "          (0): ConvNextLayerNorm()\n",
       "          (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (0): ConvNextLayer(\n",
       "            (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "            (layernorm): ConvNextLayerNorm()\n",
       "            (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELUActivation()\n",
       "            (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): ConvNextLayer(\n",
       "            (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "            (layernorm): ConvNextLayerNorm()\n",
       "            (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELUActivation()\n",
       "            (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): ConvNextLayer(\n",
       "            (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "            (layernorm): ConvNextLayerNorm()\n",
       "            (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELUActivation()\n",
       "            (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ConvNextStage(\n",
       "        (downsampling_layer): Sequential(\n",
       "          (0): ConvNextLayerNorm()\n",
       "          (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (0): ConvNextLayer(\n",
       "            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (layernorm): ConvNextLayerNorm()\n",
       "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELUActivation()\n",
       "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): ConvNextLayer(\n",
       "            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (layernorm): ConvNextLayerNorm()\n",
       "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELUActivation()\n",
       "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): ConvNextLayer(\n",
       "            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (layernorm): ConvNextLayerNorm()\n",
       "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELUActivation()\n",
       "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (3): ConvNextLayer(\n",
       "            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (layernorm): ConvNextLayerNorm()\n",
       "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELUActivation()\n",
       "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (4): ConvNextLayer(\n",
       "            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (layernorm): ConvNextLayerNorm()\n",
       "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELUActivation()\n",
       "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (5): ConvNextLayer(\n",
       "            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (layernorm): ConvNextLayerNorm()\n",
       "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELUActivation()\n",
       "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (6): ConvNextLayer(\n",
       "            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (layernorm): ConvNextLayerNorm()\n",
       "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELUActivation()\n",
       "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (7): ConvNextLayer(\n",
       "            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (layernorm): ConvNextLayerNorm()\n",
       "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELUActivation()\n",
       "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (8): ConvNextLayer(\n",
       "            (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "            (layernorm): ConvNextLayerNorm()\n",
       "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELUActivation()\n",
       "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ConvNextStage(\n",
       "        (downsampling_layer): Sequential(\n",
       "          (0): ConvNextLayerNorm()\n",
       "          (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "        )\n",
       "        (layers): Sequential(\n",
       "          (0): ConvNextLayer(\n",
       "            (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (layernorm): ConvNextLayerNorm()\n",
       "            (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELUActivation()\n",
       "            (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): ConvNextLayer(\n",
       "            (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (layernorm): ConvNextLayerNorm()\n",
       "            (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELUActivation()\n",
       "            (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): ConvNextLayer(\n",
       "            (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "            (layernorm): ConvNextLayerNorm()\n",
       "            (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELUActivation()\n",
       "            (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ROCO_69635', 'ROCO_10547', 'ROCO_73315')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, caption, _, _, img_name = next(iter(train_loader))\n",
    "img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pretrained_model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768, 7, 7])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNextDebugger(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model \n",
    "    \n",
    "    def forward(self, input):\n",
    "        out = self.model.forward(input, return_dict=False)\n",
    "        out = out[0]\n",
    "        return out \n",
    "    \n",
    "    def __call__(self, input):\n",
    "        out = self.forward(input)\n",
    "        return out \n",
    "    \n",
    "model_debug = ConvNextDebugger(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768, 7, 7])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model_debug(img)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 56, 56]           4,704\n",
      " ConvNextLayerNorm-2           [-1, 96, 56, 56]             192\n",
      "ConvNextEmbeddings-3           [-1, 96, 56, 56]               0\n",
      "          Identity-4           [-1, 96, 56, 56]               0\n",
      "            Conv2d-5           [-1, 96, 56, 56]           4,800\n",
      " ConvNextLayerNorm-6           [-1, 56, 56, 96]             192\n",
      "            Linear-7          [-1, 56, 56, 384]          37,248\n",
      "    GELUActivation-8          [-1, 56, 56, 384]               0\n",
      "    GELUActivation-9          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-10          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-11          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-12          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-13          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-14          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-15          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-16          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-17          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-18          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-19          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-20          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-21          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-22          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-23          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-24          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-25          [-1, 56, 56, 384]               0\n",
      "           Linear-26           [-1, 56, 56, 96]          36,960\n",
      "         Identity-27           [-1, 96, 56, 56]               0\n",
      "    ConvNextLayer-28           [-1, 96, 56, 56]               0\n",
      "           Conv2d-29           [-1, 96, 56, 56]           4,800\n",
      "ConvNextLayerNorm-30           [-1, 56, 56, 96]             192\n",
      "           Linear-31          [-1, 56, 56, 384]          37,248\n",
      "   GELUActivation-32          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-33          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-34          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-35          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-36          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-37          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-38          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-39          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-40          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-41          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-42          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-43          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-44          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-45          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-46          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-47          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-48          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-49          [-1, 56, 56, 384]               0\n",
      "           Linear-50           [-1, 56, 56, 96]          36,960\n",
      "         Identity-51           [-1, 96, 56, 56]               0\n",
      "    ConvNextLayer-52           [-1, 96, 56, 56]               0\n",
      "           Conv2d-53           [-1, 96, 56, 56]           4,800\n",
      "ConvNextLayerNorm-54           [-1, 56, 56, 96]             192\n",
      "           Linear-55          [-1, 56, 56, 384]          37,248\n",
      "   GELUActivation-56          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-57          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-58          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-59          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-60          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-61          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-62          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-63          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-64          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-65          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-66          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-67          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-68          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-69          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-70          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-71          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-72          [-1, 56, 56, 384]               0\n",
      "   GELUActivation-73          [-1, 56, 56, 384]               0\n",
      "           Linear-74           [-1, 56, 56, 96]          36,960\n",
      "         Identity-75           [-1, 96, 56, 56]               0\n",
      "    ConvNextLayer-76           [-1, 96, 56, 56]               0\n",
      "    ConvNextStage-77           [-1, 96, 56, 56]               0\n",
      "ConvNextLayerNorm-78           [-1, 96, 56, 56]             192\n",
      "           Conv2d-79          [-1, 192, 28, 28]          73,920\n",
      "           Conv2d-80          [-1, 192, 28, 28]           9,600\n",
      "ConvNextLayerNorm-81          [-1, 28, 28, 192]             384\n",
      "           Linear-82          [-1, 28, 28, 768]         148,224\n",
      "   GELUActivation-83          [-1, 28, 28, 768]               0\n",
      "   GELUActivation-84          [-1, 28, 28, 768]               0\n",
      "   GELUActivation-85          [-1, 28, 28, 768]               0\n",
      "   GELUActivation-86          [-1, 28, 28, 768]               0\n",
      "   GELUActivation-87          [-1, 28, 28, 768]               0\n",
      "   GELUActivation-88          [-1, 28, 28, 768]               0\n",
      "   GELUActivation-89          [-1, 28, 28, 768]               0\n",
      "   GELUActivation-90          [-1, 28, 28, 768]               0\n",
      "   GELUActivation-91          [-1, 28, 28, 768]               0\n",
      "   GELUActivation-92          [-1, 28, 28, 768]               0\n",
      "   GELUActivation-93          [-1, 28, 28, 768]               0\n",
      "   GELUActivation-94          [-1, 28, 28, 768]               0\n",
      "   GELUActivation-95          [-1, 28, 28, 768]               0\n",
      "   GELUActivation-96          [-1, 28, 28, 768]               0\n",
      "   GELUActivation-97          [-1, 28, 28, 768]               0\n",
      "   GELUActivation-98          [-1, 28, 28, 768]               0\n",
      "   GELUActivation-99          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-100          [-1, 28, 28, 768]               0\n",
      "          Linear-101          [-1, 28, 28, 192]         147,648\n",
      "        Identity-102          [-1, 192, 28, 28]               0\n",
      "   ConvNextLayer-103          [-1, 192, 28, 28]               0\n",
      "          Conv2d-104          [-1, 192, 28, 28]           9,600\n",
      "ConvNextLayerNorm-105          [-1, 28, 28, 192]             384\n",
      "          Linear-106          [-1, 28, 28, 768]         148,224\n",
      "  GELUActivation-107          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-108          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-109          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-110          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-111          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-112          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-113          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-114          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-115          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-116          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-117          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-118          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-119          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-120          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-121          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-122          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-123          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-124          [-1, 28, 28, 768]               0\n",
      "          Linear-125          [-1, 28, 28, 192]         147,648\n",
      "        Identity-126          [-1, 192, 28, 28]               0\n",
      "   ConvNextLayer-127          [-1, 192, 28, 28]               0\n",
      "          Conv2d-128          [-1, 192, 28, 28]           9,600\n",
      "ConvNextLayerNorm-129          [-1, 28, 28, 192]             384\n",
      "          Linear-130          [-1, 28, 28, 768]         148,224\n",
      "  GELUActivation-131          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-132          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-133          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-134          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-135          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-136          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-137          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-138          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-139          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-140          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-141          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-142          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-143          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-144          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-145          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-146          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-147          [-1, 28, 28, 768]               0\n",
      "  GELUActivation-148          [-1, 28, 28, 768]               0\n",
      "          Linear-149          [-1, 28, 28, 192]         147,648\n",
      "        Identity-150          [-1, 192, 28, 28]               0\n",
      "   ConvNextLayer-151          [-1, 192, 28, 28]               0\n",
      "   ConvNextStage-152          [-1, 192, 28, 28]               0\n",
      "ConvNextLayerNorm-153          [-1, 192, 28, 28]             384\n",
      "          Conv2d-154          [-1, 384, 14, 14]         295,296\n",
      "          Conv2d-155          [-1, 384, 14, 14]          19,200\n",
      "ConvNextLayerNorm-156          [-1, 14, 14, 384]             768\n",
      "          Linear-157         [-1, 14, 14, 1536]         591,360\n",
      "  GELUActivation-158         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-159         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-160         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-161         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-162         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-163         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-164         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-165         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-166         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-167         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-168         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-169         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-170         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-171         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-172         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-173         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-174         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-175         [-1, 14, 14, 1536]               0\n",
      "          Linear-176          [-1, 14, 14, 384]         590,208\n",
      "        Identity-177          [-1, 384, 14, 14]               0\n",
      "   ConvNextLayer-178          [-1, 384, 14, 14]               0\n",
      "          Conv2d-179          [-1, 384, 14, 14]          19,200\n",
      "ConvNextLayerNorm-180          [-1, 14, 14, 384]             768\n",
      "          Linear-181         [-1, 14, 14, 1536]         591,360\n",
      "  GELUActivation-182         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-183         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-184         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-185         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-186         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-187         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-188         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-189         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-190         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-191         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-192         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-193         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-194         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-195         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-196         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-197         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-198         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-199         [-1, 14, 14, 1536]               0\n",
      "          Linear-200          [-1, 14, 14, 384]         590,208\n",
      "        Identity-201          [-1, 384, 14, 14]               0\n",
      "   ConvNextLayer-202          [-1, 384, 14, 14]               0\n",
      "          Conv2d-203          [-1, 384, 14, 14]          19,200\n",
      "ConvNextLayerNorm-204          [-1, 14, 14, 384]             768\n",
      "          Linear-205         [-1, 14, 14, 1536]         591,360\n",
      "  GELUActivation-206         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-207         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-208         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-209         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-210         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-211         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-212         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-213         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-214         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-215         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-216         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-217         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-218         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-219         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-220         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-221         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-222         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-223         [-1, 14, 14, 1536]               0\n",
      "          Linear-224          [-1, 14, 14, 384]         590,208\n",
      "        Identity-225          [-1, 384, 14, 14]               0\n",
      "   ConvNextLayer-226          [-1, 384, 14, 14]               0\n",
      "          Conv2d-227          [-1, 384, 14, 14]          19,200\n",
      "ConvNextLayerNorm-228          [-1, 14, 14, 384]             768\n",
      "          Linear-229         [-1, 14, 14, 1536]         591,360\n",
      "  GELUActivation-230         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-231         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-232         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-233         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-234         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-235         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-236         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-237         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-238         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-239         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-240         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-241         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-242         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-243         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-244         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-245         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-246         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-247         [-1, 14, 14, 1536]               0\n",
      "          Linear-248          [-1, 14, 14, 384]         590,208\n",
      "        Identity-249          [-1, 384, 14, 14]               0\n",
      "   ConvNextLayer-250          [-1, 384, 14, 14]               0\n",
      "          Conv2d-251          [-1, 384, 14, 14]          19,200\n",
      "ConvNextLayerNorm-252          [-1, 14, 14, 384]             768\n",
      "          Linear-253         [-1, 14, 14, 1536]         591,360\n",
      "  GELUActivation-254         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-255         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-256         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-257         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-258         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-259         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-260         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-261         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-262         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-263         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-264         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-265         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-266         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-267         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-268         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-269         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-270         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-271         [-1, 14, 14, 1536]               0\n",
      "          Linear-272          [-1, 14, 14, 384]         590,208\n",
      "        Identity-273          [-1, 384, 14, 14]               0\n",
      "   ConvNextLayer-274          [-1, 384, 14, 14]               0\n",
      "          Conv2d-275          [-1, 384, 14, 14]          19,200\n",
      "ConvNextLayerNorm-276          [-1, 14, 14, 384]             768\n",
      "          Linear-277         [-1, 14, 14, 1536]         591,360\n",
      "  GELUActivation-278         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-279         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-280         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-281         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-282         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-283         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-284         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-285         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-286         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-287         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-288         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-289         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-290         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-291         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-292         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-293         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-294         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-295         [-1, 14, 14, 1536]               0\n",
      "          Linear-296          [-1, 14, 14, 384]         590,208\n",
      "        Identity-297          [-1, 384, 14, 14]               0\n",
      "   ConvNextLayer-298          [-1, 384, 14, 14]               0\n",
      "          Conv2d-299          [-1, 384, 14, 14]          19,200\n",
      "ConvNextLayerNorm-300          [-1, 14, 14, 384]             768\n",
      "          Linear-301         [-1, 14, 14, 1536]         591,360\n",
      "  GELUActivation-302         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-303         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-304         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-305         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-306         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-307         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-308         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-309         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-310         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-311         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-312         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-313         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-314         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-315         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-316         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-317         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-318         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-319         [-1, 14, 14, 1536]               0\n",
      "          Linear-320          [-1, 14, 14, 384]         590,208\n",
      "        Identity-321          [-1, 384, 14, 14]               0\n",
      "   ConvNextLayer-322          [-1, 384, 14, 14]               0\n",
      "          Conv2d-323          [-1, 384, 14, 14]          19,200\n",
      "ConvNextLayerNorm-324          [-1, 14, 14, 384]             768\n",
      "          Linear-325         [-1, 14, 14, 1536]         591,360\n",
      "  GELUActivation-326         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-327         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-328         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-329         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-330         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-331         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-332         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-333         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-334         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-335         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-336         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-337         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-338         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-339         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-340         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-341         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-342         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-343         [-1, 14, 14, 1536]               0\n",
      "          Linear-344          [-1, 14, 14, 384]         590,208\n",
      "        Identity-345          [-1, 384, 14, 14]               0\n",
      "   ConvNextLayer-346          [-1, 384, 14, 14]               0\n",
      "          Conv2d-347          [-1, 384, 14, 14]          19,200\n",
      "ConvNextLayerNorm-348          [-1, 14, 14, 384]             768\n",
      "          Linear-349         [-1, 14, 14, 1536]         591,360\n",
      "  GELUActivation-350         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-351         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-352         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-353         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-354         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-355         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-356         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-357         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-358         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-359         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-360         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-361         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-362         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-363         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-364         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-365         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-366         [-1, 14, 14, 1536]               0\n",
      "  GELUActivation-367         [-1, 14, 14, 1536]               0\n",
      "          Linear-368          [-1, 14, 14, 384]         590,208\n",
      "        Identity-369          [-1, 384, 14, 14]               0\n",
      "   ConvNextLayer-370          [-1, 384, 14, 14]               0\n",
      "   ConvNextStage-371          [-1, 384, 14, 14]               0\n",
      "ConvNextLayerNorm-372          [-1, 384, 14, 14]             768\n",
      "          Conv2d-373            [-1, 768, 7, 7]       1,180,416\n",
      "          Conv2d-374            [-1, 768, 7, 7]          38,400\n",
      "ConvNextLayerNorm-375            [-1, 7, 7, 768]           1,536\n",
      "          Linear-376           [-1, 7, 7, 3072]       2,362,368\n",
      "  GELUActivation-377           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-378           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-379           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-380           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-381           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-382           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-383           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-384           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-385           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-386           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-387           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-388           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-389           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-390           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-391           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-392           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-393           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-394           [-1, 7, 7, 3072]               0\n",
      "          Linear-395            [-1, 7, 7, 768]       2,360,064\n",
      "        Identity-396            [-1, 768, 7, 7]               0\n",
      "   ConvNextLayer-397            [-1, 768, 7, 7]               0\n",
      "          Conv2d-398            [-1, 768, 7, 7]          38,400\n",
      "ConvNextLayerNorm-399            [-1, 7, 7, 768]           1,536\n",
      "          Linear-400           [-1, 7, 7, 3072]       2,362,368\n",
      "  GELUActivation-401           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-402           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-403           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-404           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-405           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-406           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-407           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-408           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-409           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-410           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-411           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-412           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-413           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-414           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-415           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-416           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-417           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-418           [-1, 7, 7, 3072]               0\n",
      "          Linear-419            [-1, 7, 7, 768]       2,360,064\n",
      "        Identity-420            [-1, 768, 7, 7]               0\n",
      "   ConvNextLayer-421            [-1, 768, 7, 7]               0\n",
      "          Conv2d-422            [-1, 768, 7, 7]          38,400\n",
      "ConvNextLayerNorm-423            [-1, 7, 7, 768]           1,536\n",
      "          Linear-424           [-1, 7, 7, 3072]       2,362,368\n",
      "  GELUActivation-425           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-426           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-427           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-428           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-429           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-430           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-431           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-432           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-433           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-434           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-435           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-436           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-437           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-438           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-439           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-440           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-441           [-1, 7, 7, 3072]               0\n",
      "  GELUActivation-442           [-1, 7, 7, 3072]               0\n",
      "          Linear-443            [-1, 7, 7, 768]       2,360,064\n",
      "        Identity-444            [-1, 768, 7, 7]               0\n",
      "   ConvNextLayer-445            [-1, 768, 7, 7]               0\n",
      "   ConvNextStage-446            [-1, 768, 7, 7]               0\n",
      " ConvNextEncoder-447          [[-1, 768, 7, 7]]               0\n",
      "       LayerNorm-448                  [-1, 768]           1,536\n",
      "================================================================\n",
      "Total params: 27,813,504\n",
      "Trainable params: 27,813,504\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 1345.40\n",
      "Params size (MB): 106.10\n",
      "Estimated Total Size (MB): 1452.07\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model_debug, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNextTransferLearning(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        ...\n",
    "        # adicionar linear vazio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"_name_or_path\": \"t5-small\",\n",
       "  \"architectures\": [\n",
       "    \"T5WithLMHeadModel\"\n",
       "  ],\n",
       "  \"d_ff\": 2048,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 512,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dense_act_fn\": \"relu\",\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"relu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"is_gated_act\": false,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"n_positions\": 512,\n",
       "  \"num_decoder_layers\": 6,\n",
       "  \"num_heads\": 8,\n",
       "  \"num_layers\": 6,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_max_distance\": 128,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 200,\n",
       "      \"min_length\": 30,\n",
       "      \"no_repeat_ngram_size\": 3,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"summarize: \"\n",
       "    },\n",
       "    \"translation_en_to_de\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to German: \"\n",
       "    },\n",
       "    \"translation_en_to_fr\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to French: \"\n",
       "    },\n",
       "    \"translation_en_to_ro\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"max_length\": 300,\n",
       "      \"num_beams\": 4,\n",
       "      \"prefix\": \"translate English to Romanian: \"\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.20.0.dev0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32128\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
